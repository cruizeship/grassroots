{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1a1a46a-6559-4476-8359-ac8cb9cdbc41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests_html\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTMLSession\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests_html'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "import urllib.parse\n",
    "from ast import *\n",
    "from requests_html import HTMLSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e4856a3-5845-4e69-8c2e-f50df340c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_search_results(query, num_results):\n",
    "    # Google news search URL with query\n",
    "    search_url = f\"https://www.google.com/search?q={query}&tbm=nws&num={num_results}\"\n",
    "\n",
    "    # Send a request to Google Search\n",
    "    response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "    # Parse the response content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Extract the news headlines\n",
    "    #soup.find_all('div', class_= 'BNeawe vvjwJb AP7Wnd'):\n",
    "    \n",
    "    divs = soup.find_all('div', class_='BNeawe vvjwJb AP7Wnd')\n",
    "    articles = []\n",
    "    \n",
    "    if not divs:\n",
    "        print(\"No news results found.\")\n",
    "        return\n",
    "    \n",
    "    for div in divs:\n",
    "        # Extract headline text\n",
    "        headline = div.text\n",
    "        # Find the parent 'a' tag which contains the link\n",
    "        link_tag = div.find_parent('a')\n",
    "        # Extract the link URL\n",
    "        if link_tag:\n",
    "            # Google search results URLs are often prefixed with '/url?q='\n",
    "            # Extract and decode the actual URL using urllib.parse\n",
    "            raw_url = link_tag.get('href')\n",
    "            if raw_url.startswith('/url?q='):\n",
    "                url = urllib.parse.unquote(raw_url.split('/url?q=')[1].split('&sa=')[0])\n",
    "            else:\n",
    "                url = 'No valid link found'\n",
    "        else:\n",
    "            url = 'No link found'\n",
    "            \n",
    "        articles.append((headline, url))\n",
    "            \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99b6d5f9-ad2c-45ab-bdb0-0e296a581b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query and the number of results\n",
    "def fetch_links(location, topic):\n",
    "    query = f\"{location} local news in the past week about {topic}\"\n",
    "    num_results = 25\n",
    "    articles = []\n",
    "    \n",
    "    # Get the news search results\n",
    "    news_search_results = get_news_search_results(query, num_results)\n",
    "\n",
    "    # # Print the results\n",
    "    for i, result in enumerate(news_search_results, 1):\n",
    "    #     # print(f\"{i}. {result}\")\n",
    "         articles.append(result)\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7aa507b1-5381-42de-b43a-386cb598adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_openai(prompt):\n",
    "    api_key = \"sk-proj-f72yNKo5Aj5GpzO4ye7KT3BlbkFJFTEm12nM4PJtgNNMLR2o\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b1725da-5897-4bda-bc2d-10f450938f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_events(location, topic):\n",
    "    articles = fetch_links(location, topic)\n",
    "    \n",
    "    prompt = f\"\"\"For the following list, give me a list of five important distinct events that are referenced by several articles (i.e. a short blurb). \n",
    "    {articles} If it's not related to {topic} and/or it's not in {location}, don't account for it. If it's an opinion article or a guide, don't account for it.\n",
    "    It should be formatted as a python array of arrays, with the first item being the event title and the second item the links that pertain to it. \n",
    "    The event should be something distinct and not a general topic â€” i.e. the Golden Gate Bridge has shut down.\"\n",
    "    Please don't do things like '''python or /n, i should be able to assign the output text to a variable\n",
    "    \"\"\"\n",
    "    response_text = prompt_openai(prompt)\n",
    "    return eval(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7a65c8a-18a7-4fdd-8441-ca7de284aec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2023 APEC Summit in San Francisco',\n",
       "  ['https://www.nbcbayarea.com/news/local/apec-summit-san-francisco-explained/3369623/',\n",
       "   'https://www.sfchronicle.com/sf/article/apec-san-francisco-closures-traffic-18481349.php',\n",
       "   'https://www.nbcbayarea.com/news/local/san-francisco/san-francisco-streets-after-apec/3395312/',\n",
       "   'https://www.kqed.org/news/11965942/from-street-closures-to-security-checks-what-to-know-about-sf-apec-2023',\n",
       "   'https://www.sfchronicle.com/bayarea/article/apec-protest-san-francisco-18483819.php',\n",
       "   'https://abc7news.com/apec-summit-san-francisco-schedule-asia-pacific-economic-cooperation-2023/14028661/',\n",
       "   'https://abc7news.com/apec-2023-san-francisco-road-closures-summit-security-sf-safety/14022548/',\n",
       "   'https://www.sfchronicle.com/sf/article/apec-san-francisco-closures-traffic-18497432.php',\n",
       "   'https://www.sfchronicle.com/sf/article/sf-apec-homeless-encampments-clear-hotspots-18478050.php',\n",
       "   'https://www.sfchronicle.com/sf/article/apec-san-francisco-closures-traffic-protests-18494935.php',\n",
       "   'https://abc7news.com/apec-summit-san-francisco-road-closures-traffic/14009814/',\n",
       "   'https://sfstandard.com/2023/11/07/san-francisco-apec-security-maps-transit-traffic/']],\n",
       " ['Bay Area Job Market and Economy',\n",
       "  ['https://www.mercurynews.com/2024/05/17/bay-area-job-tech-economy-covid-layoff-hotel-restaurant-store-april/',\n",
       "   'https://www.bizjournals.com/sanfrancisco/news/2024/02/16/tri-valley-drives-economy-embraces-innovation.html',\n",
       "   'https://www.mercurynews.com/2024/05/09/economy-san-jose-oakland-downtown-jobs-restaurant-store-tech-property/',\n",
       "   'https://www.mercurynews.com/2024/04/19/bay-area-job-tech-economy-covid-layoff-hotel-restaurant-store-march/',\n",
       "   'https://www.sfchronicle.com/sf/article/san-francisco-economy-18362987.php']],\n",
       " ['Protests and Social Movements Impacting Bay Area Economy',\n",
       "  ['https://www.kqed.org/news/11982940/protesters-shut-down-880-freeway-in-oakland-as-part-of-economic-blockade-for-gaza']],\n",
       " ['Economic Impact of Events in the Bay Area',\n",
       "  ['https://www.sfchronicle.com/eastbay/article/oakland-coliseum-worker-employee-19397706.php',\n",
       "   'https://abc7news.com/2025-nba-all-star-game-san-francisco-chase-center-tourism/14019899/']],\n",
       " [\"San Francisco's Struggling Economy\",\n",
       "  ['https://www.newyorker.com/magazine/2023/10/23/what-happened-to-san-francisco-really']]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = generate_events(\"san francisco bay area\", \"economy\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dbf9f-fbfc-4c1a-af69-7bf230981355",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in output:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17573c2c-daf7-4f5b-bc9d-7e8565a7c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFirstImage("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
